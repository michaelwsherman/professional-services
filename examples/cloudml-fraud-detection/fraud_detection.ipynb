{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fraud-detection-example-private.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "AqcZQpdcOyVn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1>0. Introduction</h1>\n",
        "\n",
        "This notebook implements and runs a fraud detection model for credit-cards transactions using the Google Cloud platform. In this notebooks we will execute code to process data, train a tensorflow model, run predictions on new data and assess model performances.\n",
        "\n",
        "\n",
        "\n",
        "**Before you start, you will need to:**\n",
        "\n",
        "* Create a Google Cloud project and a bucket in Google Cloud Storage\n",
        "* Install gcloud SDK to run gcloud commands: https://cloud.google.com/sdk/downloads\n",
        "\n",
        "**You can also:**\n",
        "\n",
        "* Go through the python code available here: https://source.developers.google.com/p/fraud-detection-example/r/fraud-detection\n"
      ]
    },
    {
      "metadata": {
        "id": "O2fzNA9AXtDz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1>1. Environment set-up</h1>"
      ]
    },
    {
      "metadata": {
        "id": "EoWIK3ofXtED",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Authenticate with the gcloud command**"
      ]
    },
    {
      "metadata": {
        "id": "8mgn6yojTA1g",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kWG6ICxYXtEO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Project information**\n",
        "\n",
        "Hard-code your project information as environment variables to be used in the following steps.\n",
        "* PROJECT_ID is your GCP project ID to use for this example\n",
        "* BUCKET_ID is the name of your bucket to to store outputs for this example \n",
        "* BQ_TABLE_NAME is the name of your BQ table containing the raw data"
      ]
    },
    {
      "metadata": {
        "id": "KWzr7Dd3XtEP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "4d70df1c-cffc-4f98-c15b-d4e1507cdae7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522882324452,
          "user_tz": 240,
          "elapsed": 338,
          "user": {
            "displayName": "Arthur Argenson",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103507511977375243246"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "%env PROJECT_ID=fraud-detection-example\n",
        "%env BUCKET_ID=fraud-detection-example\n",
        "%env BQ_TABLE_NAME=raw_data"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: PROJECT_ID=fraud-detection-example\n",
            "env: BUCKET_ID=fraud-detection-example\n",
            "env: BQ_TABLE_NAME=raw_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Jux7D09NcxxK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Set your GCP project id**"
      ]
    },
    {
      "metadata": {
        "id": "SVLKSwrw5OrA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f5aa0d91-37ac-496f-d66e-ed36333a21fa",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522866134691,
          "user_tz": 240,
          "elapsed": 1017,
          "user": {
            "displayName": "Arthur Argenson",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103507511977375243246"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "gcloud config set project $PROJECT_ID"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "wE1hDBHNzQfZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Set up the dataset using Google BigQuery**\n",
        "\n",
        "In your project, create a BigQuery dataset named 'fraud_detection' and create a table from the data stored in GCP public bucket by running the command below.\n"
      ]
    },
    {
      "metadata": {
        "id": "BKQpJEYlvPAt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2facccb1-09f7-49a5-cd44-9796527e266f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522849572022,
          "user_tz": 240,
          "elapsed": 3489,
          "user": {
            "displayName": "Arthur Argenson",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103507511977375243246"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "bq load --project_id $PROJECT_ID --autodetect \\\n",
        "--source_format=CSV fraud_detection.$BQ_TABLE_NAME gs://fraud-detection-example/creditcard_proc.csv"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Process is interrupted.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A_v9ATnfXtEF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Clone the git repository containing the necessary code**\n",
        "\n",
        "It contains python code to process data, train a tensorflow model and run predictions."
      ]
    },
    {
      "metadata": {
        "id": "oN_HMpzFOyWR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "074314ae-1027-43af-d96e-ff241b05107f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522863398141,
          "user_tz": 240,
          "elapsed": 2303,
          "user": {
            "displayName": "Arthur Argenson",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103507511977375243246"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!gcloud source repos clone fraud-detection --project=fraud-detection-example"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;31mERROR:\u001b[0m (gcloud.source.repos.clone) Directory path specified exists and is not empty\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3buGJ-WWZFzS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Note: you may need to request access to the GCP bucket and repository**"
      ]
    },
    {
      "metadata": {
        "id": "0AdEHrw6XtEL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Current timestamp for unique naming**\n",
        "\n",
        "We use the current timestamp as a string to ensure unique naming through the different steps of the process."
      ]
    },
    {
      "metadata": {
        "id": "zenhdMKSXtEL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d17c931-31ad-46a7-bfda-6e9c19e22087",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522863398563,
          "user_tz": 240,
          "elapsed": 400,
          "user": {
            "displayName": "Arthur Argenson",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103507511977375243246"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "current_time = str(time.time()).replace('.', '')\n",
        "current_time"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'152286339827'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "29Cv225aXtES",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1>2. Run data preprocessing in Google Cloud Dataflow</h1>"
      ]
    },
    {
      "metadata": {
        "id": "3yfSnDRMXtET",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this part we run the data preprocessing in Google Cloud Dataflow using the Apache-Beam and Tensorflow-Transform libraries.\n",
        "\n",
        "This step includes the following:\n",
        "- reads data from BigQuery\n",
        "- adds hash key value to each row\n",
        "- scales data\n",
        "- shuffles and splits data in train / validation / test sets\n",
        "- oversamples train data\n",
        "- stores data as TFRecord\n",
        "- splits and stores test data into labels and features files"
      ]
    },
    {
      "metadata": {
        "id": "GgO79t8NXtEU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Output path**\n",
        "\n",
        "Hard-code the output path of data processing to be used in the following steps."
      ]
    },
    {
      "metadata": {
        "id": "4oOoiwndT2qi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "16519438-f4cf-48b5-da90-71b4bf65252c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522863403913,
          "user_tz": 240,
          "elapsed": 1410,
          "user": {
            "displayName": "Arthur Argenson",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103507511977375243246"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "os.environ['DATAFLOW_OUTPUT_DIR'] = 'data_flow_output_dir-{}/'.format(\n",
        "    current_time)\n",
        "!echo $DATAFLOW_OUTPUT_DIR"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data_flow_output_dir-152286339827/\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cH51ynx11lA2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Note: depending on your configuration, you may need to install missing python packages**"
      ]
    },
    {
      "metadata": {
        "id": "chJbiUOX1MmM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1312
        },
        "outputId": "3f71c8d1-a142-435b-8ef8-414324eac915",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522863409699,
          "user_tz": 240,
          "elapsed": 5284,
          "user": {
            "displayName": "Arthur Argenson",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103507511977375243246"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install apache_beam==2.4.0\n",
        "!pip install tensorflow-transform==0.4.0"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: apache_beam==2.4.0 in /usr/local/lib/python2.7/dist-packages\n",
            "Requirement already satisfied: dill==0.2.6 in /usr/local/lib/python2.7/dist-packages (from apache_beam==2.4.0)\n",
            "Requirement already satisfied: pyyaml<4.0.0,>=3.12 in /usr/local/lib/python2.7/dist-packages (from apache_beam==2.4.0)\n",
            "Requirement already satisfied: futures<4.0.0,>=3.1.1 in /usr/local/lib/python2.7/dist-packages (from apache_beam==2.4.0)\n",
            "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python2.7/dist-packages (from apache_beam==2.4.0)\n",
            "Requirement already satisfied: pyvcf<0.7.0,>=0.6.8 in /usr/local/lib/python2.7/dist-packages (from apache_beam==2.4.0)\n",
            "Requirement already satisfied: httplib2<0.10,>=0.8 in /usr/local/lib/python2.7/dist-packages (from apache_beam==2.4.0)\n",
            "Requirement already satisfied: avro<2.0.0,>=1.8.1 in /usr/local/lib/python2.7/dist-packages (from apache_beam==2.4.0)\n",
            "Requirement already satisfied: mock<3.0.0,>=1.0.1 in /usr/local/lib/python2.7/dist-packages (from apache_beam==2.4.0)\n",
            "Requirement already satisfied: typing<3.7.0,>=3.6.0 in /usr/local/lib/python2.7/dist-packages (from apache_beam==2.4.0)\n",
            "Requirement already satisfied: grpcio<2,>=1.0 in /usr/local/lib/python2.7/dist-packages (from apache_beam==2.4.0)\n",
            "Requirement already satisfied: six<1.12,>=1.9 in /usr/local/lib/python2.7/dist-packages (from apache_beam==2.4.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.5.0.post1 in /usr/local/lib/python2.7/dist-packages (from apache_beam==2.4.0)\n",
            "Requirement already satisfied: oauth2client<5,>=2.0.1 in /usr/local/lib/python2.7/dist-packages (from apache_beam==2.4.0)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python2.7/dist-packages (from apache_beam==2.4.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python2.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache_beam==2.4.0)\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python2.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache_beam==2.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python2.7/dist-packages (from pyvcf<0.7.0,>=0.6.8->apache_beam==2.4.0)\n",
            "Requirement already satisfied: funcsigs>=1; python_version < \"3.3\" in /usr/local/lib/python2.7/dist-packages (from mock<3.0.0,>=1.0.1->apache_beam==2.4.0)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock<3.0.0,>=1.0.1->apache_beam==2.4.0)\n",
            "Requirement already satisfied: enum34>=1.0.4 in /usr/local/lib/python2.7/dist-packages (from grpcio<2,>=1.0->apache_beam==2.4.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from oauth2client<5,>=2.0.1->apache_beam==2.4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python2.7/dist-packages (from oauth2client<5,>=2.0.1->apache_beam==2.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python2.7/dist-packages (from oauth2client<5,>=2.0.1->apache_beam==2.4.0)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache_beam==2.4.0)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache_beam==2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache_beam==2.4.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache_beam==2.4.0)\n",
            "Requirement already satisfied: tensorflow-transform==0.4.0 in /usr/local/lib/python2.7/dist-packages\n",
            "Requirement already satisfied: six<1.11,>=1.9 in /usr/local/lib/python2.7/dist-packages (from tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: apache-beam[gcp]<3,>=2.2 in /usr/local/lib/python2.7/dist-packages (from tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.3 in /usr/local/lib/python2.7/dist-packages (from tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: dill==0.2.6 in /usr/local/lib/python2.7/dist-packages (from apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: pyyaml<4.0.0,>=3.12 in /usr/local/lib/python2.7/dist-packages (from apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: futures<4.0.0,>=3.1.1 in /usr/local/lib/python2.7/dist-packages (from apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python2.7/dist-packages (from apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: pyvcf<0.7.0,>=0.6.8 in /usr/local/lib/python2.7/dist-packages (from apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: grpcio<2,>=1.0 in /usr/local/lib/python2.7/dist-packages (from apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: avro<2.0.0,>=1.8.1 in /usr/local/lib/python2.7/dist-packages (from apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: mock<3.0.0,>=1.0.1 in /usr/local/lib/python2.7/dist-packages (from apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: typing<3.7.0,>=3.6.0 in /usr/local/lib/python2.7/dist-packages (from apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: httplib2<0.10,>=0.8 in /usr/local/lib/python2.7/dist-packages (from apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: oauth2client<5,>=2.0.1 in /usr/local/lib/python2.7/dist-packages (from apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python2.7/dist-packages (from apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: google-apitools<=0.5.20,>=0.5.18; extra == \"gcp\" in /usr/local/lib/python2.7/dist-packages (from apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: google-cloud-bigquery==0.25.0; extra == \"gcp\" in /usr/local/lib/python2.7/dist-packages (from apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: google-cloud-pubsub==0.26.0; extra == \"gcp\" in /usr/local/lib/python2.7/dist-packages (from apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: proto-google-cloud-datastore-v1<=0.90.4,>=0.90.0; extra == \"gcp\" in /usr/local/lib/python2.7/dist-packages (from apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: googledatastore==7.0.1; extra == \"gcp\" in /usr/local/lib/python2.7/dist-packages (from apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python2.7/dist-packages (from protobuf<4,>=3.3->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python2.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python2.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: enum34>=1.0.4 in /usr/local/lib/python2.7/dist-packages (from grpcio<2,>=1.0->apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: funcsigs>=1; python_version < \"3.3\" in /usr/local/lib/python2.7/dist-packages (from mock<3.0.0,>=1.0.1->apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock<3.0.0,>=1.0.1->apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python2.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python2.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: fasteners>=0.14 in /usr/local/lib/python2.7/dist-packages (from google-apitools<=0.5.20,>=0.5.18; extra == \"gcp\"->apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: google-cloud-core<0.26dev,>=0.25.0 in /usr/local/lib/python2.7/dist-packages (from google-cloud-bigquery==0.25.0; extra == \"gcp\"->apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: gapic-google-cloud-pubsub-v1<0.16dev,>=0.15.0 in /usr/local/lib/python2.7/dist-packages (from google-cloud-pubsub==0.26.0; extra == \"gcp\"->apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.5.2 in /usr/local/lib/python2.7/dist-packages (from proto-google-cloud-datastore-v1<=0.90.4,>=0.90.0; extra == \"gcp\"->apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: monotonic>=0.1 in /usr/local/lib/python2.7/dist-packages (from fasteners>=0.14->google-apitools<=0.5.20,>=0.5.18; extra == \"gcp\"->apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: google-auth-httplib2 in /usr/local/lib/python2.7/dist-packages (from google-cloud-core<0.26dev,>=0.25.0->google-cloud-bigquery==0.25.0; extra == \"gcp\"->apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: google-auth<2.0.0dev,>=0.4.0 in /usr/local/lib/python2.7/dist-packages (from google-cloud-core<0.26dev,>=0.25.0->google-cloud-bigquery==0.25.0; extra == \"gcp\"->apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: grpc-google-iam-v1<0.12dev,>=0.11.1 in /usr/local/lib/python2.7/dist-packages (from gapic-google-cloud-pubsub-v1<0.16dev,>=0.15.0->google-cloud-pubsub==0.26.0; extra == \"gcp\"->apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: proto-google-cloud-pubsub-v1[grpc]<0.16dev,>=0.15.4 in /usr/local/lib/python2.7/dist-packages (from gapic-google-cloud-pubsub-v1<0.16dev,>=0.15.0->google-cloud-pubsub==0.26.0; extra == \"gcp\"->apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: google-gax<0.16dev,>=0.15.7 in /usr/local/lib/python2.7/dist-packages (from gapic-google-cloud-pubsub-v1<0.16dev,>=0.15.0->google-cloud-pubsub==0.26.0; extra == \"gcp\"->apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth<2.0.0dev,>=0.4.0->google-cloud-core<0.26dev,>=0.25.0->google-cloud-bigquery==0.25.0; extra == \"gcp\"->apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: ply==3.8 in /usr/local/lib/python2.7/dist-packages (from google-gax<0.16dev,>=0.15.7->gapic-google-cloud-pubsub-v1<0.16dev,>=0.15.0->google-cloud-pubsub==0.26.0; extra == \"gcp\"->apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n",
            "Requirement already satisfied: future<0.17dev,>=0.16.0 in /usr/local/lib/python2.7/dist-packages (from google-gax<0.16dev,>=0.15.7->gapic-google-cloud-pubsub-v1<0.16dev,>=0.15.0->google-cloud-pubsub==0.26.0; extra == \"gcp\"->apache-beam[gcp]<3,>=2.2->tensorflow-transform==0.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D7oQpxe6XtEY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Launch data processing job**\n",
        "\n",
        "You need to specify the name of the table you stored in BigQuery and input it with the '--bq_table' argument."
      ]
    },
    {
      "metadata": {
        "id": "OtR1QeB4T3NX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "outputId": "07209d70-97fe-4f62-b043-0fba84aa6534",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522864510544,
          "user_tz": 240,
          "elapsed": 1100804,
          "user": {
            "displayName": "Arthur Argenson",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103507511977375243246"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd fraud-detection/\n",
        "python preprocess.py \\\n",
        "--cloud \\\n",
        "--bq_table $BQ_TABLE_NAME \\\n",
        "--output_dir ${DATAFLOW_OUTPUT_DIR} \\\n",
        "--project_id $PROJECT_ID \\\n",
        "--bucket_id $BUCKET_ID"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running sdist\n",
            "running egg_info\n",
            "writing requirements to trainer.egg-info/requires.txt\n",
            "writing trainer.egg-info/PKG-INFO\n",
            "writing top-level names to trainer.egg-info/top_level.txt\n",
            "writing dependency_links to trainer.egg-info/dependency_links.txt\n",
            "reading manifest file 'trainer.egg-info/SOURCES.txt'\n",
            "writing manifest file 'trainer.egg-info/SOURCES.txt'\n",
            "running check\n",
            "creating trainer-1.0\n",
            "creating trainer-1.0/constants\n",
            "creating trainer-1.0/trainer\n",
            "creating trainer-1.0/trainer.egg-info\n",
            "creating trainer-1.0/utils\n",
            "copying files to trainer-1.0...\n",
            "copying setup.py -> trainer-1.0\n",
            "copying constants/__init__.py -> trainer-1.0/constants\n",
            "copying constants/constants.py -> trainer-1.0/constants\n",
            "copying trainer/__init__.py -> trainer-1.0/trainer\n",
            "copying trainer/input_fn_utils.py -> trainer-1.0/trainer\n",
            "copying trainer/metrics.py -> trainer-1.0/trainer\n",
            "copying trainer/model.py -> trainer-1.0/trainer\n",
            "copying trainer/task.py -> trainer-1.0/trainer\n",
            "copying trainer.egg-info/PKG-INFO -> trainer-1.0/trainer.egg-info\n",
            "copying trainer.egg-info/SOURCES.txt -> trainer-1.0/trainer.egg-info\n",
            "copying trainer.egg-info/dependency_links.txt -> trainer-1.0/trainer.egg-info\n",
            "copying trainer.egg-info/requires.txt -> trainer-1.0/trainer.egg-info\n",
            "copying trainer.egg-info/top_level.txt -> trainer-1.0/trainer.egg-info\n",
            "copying utils/__init__.py -> trainer-1.0/utils\n",
            "copying utils/datasettype.py -> trainer-1.0/utils\n",
            "Writing trainer-1.0/setup.cfg\n",
            "Creating tar archive\n",
            "removing 'trainer-1.0' (and everything under it)\n",
            "Collecting apache-beam==2.4.0\n",
            "  Using cached apache-beam-2.4.0.zip\n",
            "  Saved /tmp/tmpvJQ3P6/apache-beam-2.4.0.zip\n",
            "Successfully downloaded apache-beam\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  from ._conv import register_converters as _register_converters\n",
            "warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\n",
            "\n",
            "warning: check: missing required meta-data: url\n",
            "\n",
            "warning: check: missing meta-data: either (author and author_email) or (maintainer and maintainer_email) must be supplied\n",
            "\n",
            "/usr/local/lib/python2.7/dist-packages/apache_beam/io/gcp/gcsio.py:166: DeprecationWarning: object() takes no parameters\n",
            "  super(GcsIO, cls).__new__(cls, storage_client))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "BPoZbDLZXtEe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1>3. Training in Google Cloud ML-engine</h1>"
      ]
    },
    {
      "metadata": {
        "id": "M4-DIMWBXtEf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Set up environment variables**\n",
        "\n",
        "Hard-code the output path for the training sep as well as the job name, to be used in the following steps."
      ]
    },
    {
      "metadata": {
        "id": "EsSTt2nsXtEf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "af3e1fd6-a988-4cd5-f8ba-e201b4dd5932",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522866072568,
          "user_tz": 240,
          "elapsed": 351,
          "user": {
            "displayName": "Arthur Argenson",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103507511977375243246"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "os.environ['TRAINING_JOB_NAME'] = 'fraud_detection_training_job_{}'.format(\n",
        "    current_time)\n",
        "os.environ['TRAINING_OUTPUT_DIR'] = 'gs://{}/training_output_dir-{}'.format(\n",
        "    os.environ['BUCKET_ID'], current_time)\n",
        "print os.environ['TRAINING_JOB_NAME'], os.environ['TRAINING_OUTPUT_DIR']"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aarg_fraud_detection_training_job_152286339827 gs://fraud-detection-example/training_output_dir-152286339827\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2-FeHT3EXtEi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Set hyperparameters search configuration**\n",
        "\n",
        "The training step includes hyperparameter tuning. Hyperparameter tuning (described in more details here: https://cloud.google.com/blog/big-data/2018/03/hyperparameter-tuning-on-google-cloud-platform-is-now-faster-and-smarter) is the concept of training and evaluating different parametrizations of a model to then pick the best performing one.\n",
        "For this purpose we need to indicate which parameters we want to test and the range we want to try.\n",
        "\n",
        "The ML-engine command takes in input a '.yaml' file that contains the configuration to use for hyperparameter tuning."
      ]
    },
    {
      "metadata": {
        "id": "9u6UFS9xXtEj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fa3dec7b-f5ac-42b9-a4bd-31139c0563d7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522866075276,
          "user_tz": 240,
          "elapsed": 373,
          "user": {
            "displayName": "Arthur Argenson",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103507511977375243246"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "%%writefile fraud-detection/hyperparams.yaml\n",
        "trainingInput:\n",
        "  scaleTier: STANDARD_1\n",
        "  hyperparameters:\n",
        "    maxTrials: 10\n",
        "    maxParallelTrials: 2\n",
        "    enableTrialEarlyStopping: True\n",
        "    goal: MAXIMIZE\n",
        "    hyperparameterMetricTag: auc_precision_recall\n",
        "    params:\n",
        "    - parameterName: first_layer_size\n",
        "      type: INTEGER\n",
        "      minValue: 5\n",
        "      maxValue: 50\n",
        "      scaleType: UNIT_LINEAR_SCALE\n",
        "    - parameterName: num_layers\n",
        "      type: INTEGER\n",
        "      discreteValues:\n",
        "      minValue: 1\n",
        "      maxValue: 2\n",
        "      scaleType: UNIT_LINEAR_SCALE\n",
        "    - parameterName: dropout\n",
        "      type: DOUBLE\n",
        "      minValue: 0.10\n",
        "      maxValue: 0.50\n",
        "      scaleType: UNIT_LINEAR_SCALE\n",
        "    - parameterName: learning_rate\n",
        "      type: DOUBLE\n",
        "      minValue: 0.0001\n",
        "      maxValue: 0.1\n",
        "      scaleType: UNIT_LOG_SCALE"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting fraud-detection/hyperparams.yaml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gOUlmoKXXtEl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Submit training job**\n",
        "\n",
        "You can specify the maximum number of training steps with the '--max_steps' argument."
      ]
    },
    {
      "metadata": {
        "id": "e3KKI8ZaXtEn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "8be59ac1-190c-461d-b83b-87b2cca24077",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522866146375,
          "user_tz": 240,
          "elapsed": 3227,
          "user": {
            "displayName": "Arthur Argenson",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103507511977375243246"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd fraud-detection/\n",
        "gcloud ml-engine jobs submit training $TRAINING_JOB_NAME \\\n",
        "--module-name trainer.task \\\n",
        "--staging-bucket gs://${BUCKET_ID} \\\n",
        "--package-path ./trainer \\\n",
        "--region=us-central1 \\\n",
        "--runtime-version 1.4 \\\n",
        "--config=hyperparams.yaml \\\n",
        "-- \\\n",
        "--input_dir gs://${BUCKET_ID}/${DATAFLOW_OUTPUT_DIR} \\\n",
        "--output_dir ${TRAINING_OUTPUT_DIR} \\\n",
        "--max_steps 10000"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "jobId: aarg_fraud_detection_training_job_152286339827\n",
            "state: QUEUED\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Job [aarg_fraud_detection_training_job_152286339827] submitted successfully.\n",
            "Your job is still active. You may view the status of your job with the command\n",
            "\n",
            "  $ gcloud ml-engine jobs describe aarg_fraud_detection_training_job_152286339827\n",
            "\n",
            "or continue streaming the logs with the command\n",
            "\n",
            "  $ gcloud ml-engine jobs stream-logs aarg_fraud_detection_training_job_152286339827\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "_Qwdf7W8XtEr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Monitor with Tensorboard**\n",
        "\n",
        "You can monitor in real-time the training of each model using Tensorboard. It allows to visualize different metrics such as the loss on the training and validation data.\n",
        "\n",
        "In addition you can visualize the following validation metrics to assess the evolution of your model's performances through training:\n",
        "- ROC AUC\n",
        "- Precision-recall AUC\n",
        "- Accuracy\n",
        "- Other custom metrics"
      ]
    },
    {
      "metadata": {
        "id": "c5Q2zQL1BmAg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Select which trial to visualize**\n",
        "\n",
        "Here 1"
      ]
    },
    {
      "metadata": {
        "id": "uu9smP1hAipe",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3dc26e1e-4a4b-46a6-89c1-5953c41b03bf",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522868362345,
          "user_tz": 240,
          "elapsed": 436,
          "user": {
            "displayName": "Arthur Argenson",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103507511977375243246"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "%env TRIAL_NUMBER=1"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: TRIAL_NUMBER=1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0ZYA8ZOpATIM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Run the following command on your local machine:**\n",
        "```TRIAL_NUMBER=1\n",
        "tensorboard --logdir=<TRAINING_OUTPUT_DIR>/trials/$TRIAL_NUMBER\n",
        "```\n",
        "Replace ```<TRAINING_OUTPUT_DIR>``` with the actual training output path. You can copy the output of the following cell:\n"
      ]
    },
    {
      "metadata": {
        "id": "02FiUNhSBRet",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "66d5328e-d43c-4d56-a853-1bcac1520398",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522868366318,
          "user_tz": 240,
          "elapsed": 1371,
          "user": {
            "displayName": "Arthur Argenson",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103507511977375243246"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "! echo tensorboard --logdir=$TRAINING_OUTPUT_DIR/trials/$TRIAL_NUMBER"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorboard --logdir=gs://fraud-detection-example/training_output_dir-152286339827/trials/1\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m55zdrd7XtEu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Monitor overall training in Google Cloud ML-engine**\n",
        "\n",
        "You can also monitor the overall training in GCP, access the logs and results of hyperparameter tuning in the ML-engine console:\n",
        "\n",
        "https://cloud.google.com/ml-engine/"
      ]
    },
    {
      "metadata": {
        "id": "wJKwdX1BXtEv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1>4. Inferences in Google Cloud ML-engine</h1>"
      ]
    },
    {
      "metadata": {
        "id": "YHE6pzkhXtEv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Once our model is trained and stored in Google Cloud Storage, we can add it to Cloud ML-engine and use it for batch inference on new data, among other things.\n",
        "Different versions of a same model can be stored in the ML-engine. We will specify a name for the model and a unique name for the current version, based on current timestamp."
      ]
    },
    {
      "metadata": {
        "id": "OfgazJtMe5At",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Specify the best model trial to use**\n",
        "\n",
        "After hyperparameter tuning we may have to pick between different trials and select the best performing one to use for inference. The next command defines which version to use moving forward. In this example the trial picked is 'TRIAL_NUMBER=1' but **you should adapt to pick the best performing model that you obtained after training.**"
      ]
    },
    {
      "metadata": {
        "id": "k1IPrVQ2fh0J",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c6eb646-2601-411b-ec6b-c342cb8805b2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522892944080,
          "user_tz": 240,
          "elapsed": 408,
          "user": {
            "displayName": "Arthur Argenson",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103507511977375243246"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "%env TRIAL_NUMBER=1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: TRIAL_NUMBER=7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QGkxEg4MXtEv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Set up environment variables**"
      ]
    },
    {
      "metadata": {
        "id": "wKg3XVP8XtEw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9a3361de-94aa-43fe-e53e-05391f0f8198",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522871817231,
          "user_tz": 240,
          "elapsed": 3694,
          "user": {
            "displayName": "Arthur Argenson",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103507511977375243246"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "os.environ['MODEL_NAME'] = 'fraud_detection_test_nb'\n",
        "os.environ['MODEL_VERSION'] = 'v_{}'.format(time.time()).replace('.', '')\n",
        "temp = !echo $(gsutil ls ${TRAINING_OUTPUT_DIR}/trials/${TRIAL_NUMBER}/export/exporter/ | tail -1)\n",
        "os.environ['MODEL_SAVED_NAME'] = temp[0]\n",
        "del temp\n",
        "print os.environ['MODEL_SAVED_NAME']"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: TRIAL_NUMBER=7\n",
            "gs://fraud-detection-example/training_output_dir-152286339827/trials/7/export/exporter/1522868643/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LBIx7-5NXtEy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Create and save model in Google Cloud ML-engine**\n",
        "\n",
        "We first need to add our trained model to Cloud ML-engine. We provide the path to the model we would like to use in Google Cloud Storage.."
      ]
    },
    {
      "metadata": {
        "id": "tx2OIvHyOe2_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "2b0f774e-ec16-41c0-df8a-aead26d3a1da",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522871819960,
          "user_tz": 240,
          "elapsed": 1380,
          "user": {
            "displayName": "Arthur Argenson",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103507511977375243246"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "gcloud ml-engine models create $MODEL_NAME \\\n",
        "--regions us-central1"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR: (gcloud.ml-engine.models.create) Resource in project [fraud-detection-example] is the subject of a conflict: Field: model.name Error: A model with the same name already exists.\n",
            "- '@type': type.googleapis.com/google.rpc.BadRequest\n",
            "  fieldViolations:\n",
            "  - description: A model with the same name already exists.\n",
            "    field: model.name\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "EbmBQ3cBfsyh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ".. and add the current version to the GCP model created."
      ]
    },
    {
      "metadata": {
        "id": "NR_7-pBMXtEy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "6d07f2e7-ac05-4859-d9e1-128edb58d15b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522871989069,
          "user_tz": 240,
          "elapsed": 167206,
          "user": {
            "displayName": "Arthur Argenson",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103507511977375243246"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "gcloud ml-engine versions create $MODEL_VERSION \\\n",
        "--model $MODEL_NAME \\\n",
        "--origin $MODEL_SAVED_NAME \\\n",
        "--runtime-version 1.4"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating version (this might take a few minutes)......\n",
            "....................................................................................................................................................................................................done.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "83OwbdtIXtE1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Set up environment variables**\n",
        "\n",
        "We need to specify the following:\n",
        "\n",
        "* JOB_NAME: unique name for inference job\n",
        "* FEATURES_INPUT_PATH: the path to the features to use for prediction (here it is in the output of the DataFlow job)\n",
        "* PREDICTIONS_OUTPUT_PATH: the path to the directory to store the predictions to."
      ]
    },
    {
      "metadata": {
        "id": "MlrZh45TXtE1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "29422acb-d66a-42c6-8093-114c9dc1f0cb",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522872503367,
          "user_tz": 240,
          "elapsed": 403,
          "user": {
            "displayName": "Arthur Argenson",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103507511977375243246"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "os.environ['JOB_NAME'] = '{}_{}'.format(\n",
        "    os.environ['MODEL_NAME'],\n",
        "    os.environ['MODEL_VERSION'])\n",
        "os.environ['FEATURES_INPUT_PATH'] = 'gs://{}/{}split_data/split_data_TEST_features.txt*'.format(\n",
        "    os.environ['BUCKET_ID'],\n",
        "    os.environ['DATAFLOW_OUTPUT_DIR'])\n",
        "os.environ['PREDICTIONS_OUTPUT_PATH'] = 'gs://{}/predictions/{}'.format(\n",
        "    os.environ['BUCKET_ID'],\n",
        "    os.environ['JOB_NAME'])\n",
        "print os.environ['FEATURES_INPUT_PATH']\n",
        "print os.environ['PREDICTIONS_OUTPUT_PATH']\n",
        "print os.environ['JOB_NAME']"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gs://fraud-detection-example/data_flow_output_dir-152286339827/split_data/split_data_TEST_features.txt*\n",
            "gs://fraud-detection-example/predictions/aarg_fraud_detection_test_nb_v_152287181365\n",
            "aarg_fraud_detection_test_nb_v_152287181365\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "paRnUsWjXtE5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Submit prediction job**\n",
        "\n",
        "Now that the model is saved, we can launch a training job by indicating the name of the model we just stored and the path to the data to be scored (here the test sample data from the DataFlow step)."
      ]
    },
    {
      "metadata": {
        "id": "5s175Je-XtE5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "b7c2c533-2d20-4084-a8aa-9cfde3612a30",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522872511602,
          "user_tz": 240,
          "elapsed": 3550,
          "user": {
            "displayName": "Arthur Argenson",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103507511977375243246"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "gcloud ml-engine jobs submit prediction $JOB_NAME \\\n",
        "--model $MODEL_NAME \\\n",
        "--input-paths $FEATURES_INPUT_PATH \\\n",
        "--output-path $PREDICTIONS_OUTPUT_PATH \\\n",
        "--region us-central1 \\\n",
        "--data-format TEXT \\\n",
        "--version $MODEL_VERSION"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "jobId: aarg_fraud_detection_test_nb_v_152287181365\n",
            "state: QUEUED\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Job [aarg_fraud_detection_test_nb_v_152287181365] submitted successfully.\n",
            "Your job is still active. You may view the status of your job with the command\n",
            "\n",
            "  $ gcloud ml-engine jobs describe aarg_fraud_detection_test_nb_v_152287181365\n",
            "\n",
            "or continue streaming the logs with the command\n",
            "\n",
            "  $ gcloud ml-engine jobs stream-logs aarg_fraud_detection_test_nb_v_152287181365\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "VB_Z2jnHJkfx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Monitor prediction job in Google Cloud ML-engine**\n",
        "\n",
        "You can monitor the prediction job in the GCP ML-engine console:\n",
        "\n",
        "https://cloud.google.com/ml-engine/"
      ]
    },
    {
      "metadata": {
        "id": "kVv54jVdXtE9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1>5. Assess model performances on out-of-sample data</h1>\n",
        "\n",
        "We can assess how well our model performed on the out-of-sample data previously scored. For this purpose we will compare predictions to true labels and derive the precision-recall curve and its AUC. Precision-recall curve AUC is a relevant metric to assess our model's performances as it reflects the fraction of the fraudulent transactions we are able to predict and the accuracy of these predictions."
      ]
    },
    {
      "metadata": {
        "id": "5Xhb4UxBXtE-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Prepare data**\n",
        "\n",
        "First, let's pull our predictions and true labels from Cloud Storage to our local environment in a 'predictions.txt' and 'labels.txt' file."
      ]
    },
    {
      "metadata": {
        "id": "k869CwkDXtE_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "f6eecde7-4ac9-4a0a-e219-a50ec33e5bc1",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522873056074,
          "user_tz": 240,
          "elapsed": 8522,
          "user": {
            "displayName": "Arthur Argenson",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103507511977375243246"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "ANALYSIS_OUTPUT_PATH=.\n",
        "mkdir ${ANALYSIS_OUTPUT_PATH}/labels\n",
        "gsutil cp gs://${BUCKET_ID}/${DATAFLOW_OUTPUT_DIR}split_data/split_data_TEST_labels.txt* labels/\n",
        "cat ${ANALYSIS_OUTPUT_PATH}/labels/* > ${ANALYSIS_OUTPUT_PATH}/labels.txt\n",
        "\n",
        "mkdir ${ANALYSIS_OUTPUT_PATH}/predictions\n",
        "gsutil cp ${PREDICTIONS_OUTPUT_PATH}/prediction.results* ./predictions/\n",
        "cat ${ANALYSIS_OUTPUT_PATH}/predictions/* > ${ANALYSIS_OUTPUT_PATH}/predictions.txt"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘./labels’: File exists\n",
            "Copying gs://fraud-detection-example/data_flow_output_dir-152286339827/split_data/split_data_TEST_labels.txt-00000-of-00011...\n",
            "/ [0 files][    0.0 B/521.0 KiB]                                                \r/ [1 files][521.0 KiB/521.0 KiB]                                                \rCopying gs://fraud-detection-example/data_flow_output_dir-152286339827/split_data/split_data_TEST_labels.txt-00001-of-00011...\n",
            "/ [1 files][521.0 KiB/830.5 KiB]                                                \r/ [2 files][830.5 KiB/830.5 KiB]                                                \rCopying gs://fraud-detection-example/data_flow_output_dir-152286339827/split_data/split_data_TEST_labels.txt-00002-of-00011...\n",
            "/ [2 files][830.5 KiB/  1.1 MiB]                                                \r/ [3 files][  1.1 MiB/  1.1 MiB]                                                \rCopying gs://fraud-detection-example/data_flow_output_dir-152286339827/split_data/split_data_TEST_labels.txt-00003-of-00011...\n",
            "/ [3 files][  1.1 MiB/  1.3 MiB]                                                \r-\r- [4 files][  1.3 MiB/  1.3 MiB]                                                \r\n",
            "==> NOTE: You are performing a sequence of gsutil operations that may\n",
            "run significantly faster if you instead use gsutil -m -o ... Please\n",
            "see the -m section under \"gsutil help options\" for further information\n",
            "about when gsutil -m can be advantageous.\n",
            "\n",
            "Copying gs://fraud-detection-example/data_flow_output_dir-152286339827/split_data/split_data_TEST_labels.txt-00004-of-00011...\n",
            "- [4 files][  1.3 MiB/  1.6 MiB]                                                \r- [5 files][  1.6 MiB/  1.6 MiB]                                                \rCopying gs://fraud-detection-example/data_flow_output_dir-152286339827/split_data/split_data_TEST_labels.txt-00005-of-00011...\n",
            "- [5 files][  1.6 MiB/  1.7 MiB]                                                \r- [6 files][  1.7 MiB/  1.7 MiB]                                                \rCopying gs://fraud-detection-example/data_flow_output_dir-152286339827/split_data/split_data_TEST_labels.txt-00006-of-00011...\n",
            "- [6 files][  1.7 MiB/  1.8 MiB]                                                \r\\\r\\ [7 files][  1.8 MiB/  1.8 MiB]                                                \rCopying gs://fraud-detection-example/data_flow_output_dir-152286339827/split_data/split_data_TEST_labels.txt-00007-of-00011...\n",
            "\\ [7 files][  1.8 MiB/  2.1 MiB]                                                \r\\ [8 files][  2.1 MiB/  2.1 MiB]                                                \rCopying gs://fraud-detection-example/data_flow_output_dir-152286339827/split_data/split_data_TEST_labels.txt-00008-of-00011...\n",
            "\\ [8 files][  2.1 MiB/  2.6 MiB]                                                \r\\ [9 files][  2.6 MiB/  2.6 MiB]                                                \rCopying gs://fraud-detection-example/data_flow_output_dir-152286339827/split_data/split_data_TEST_labels.txt-00009-of-00011...\n",
            "\\ [9 files][  2.6 MiB/  2.9 MiB]                                                \r\\ [10 files][  2.9 MiB/  2.9 MiB]                                               \rCopying gs://fraud-detection-example/data_flow_output_dir-152286339827/split_data/split_data_TEST_labels.txt-00010-of-00011...\n",
            "\\ [10 files][  2.9 MiB/  3.4 MiB]                                               \r|\r| [11 files][  3.4 MiB/  3.4 MiB]                                               \r\n",
            "Operation completed over 11 objects/3.4 MiB.                                     \n",
            "mkdir: cannot create directory ‘./predictions’: File exists\n",
            "Copying gs://fraud-detection-example/predictions/aarg_fraud_detection_test_nb_v_152287181365/prediction.results-00000-of-00011...\n",
            "/ [0 files][    0.0 B/  1.1 MiB]                                                \r/ [1 files][  1.1 MiB/  1.1 MiB]                                                \rCopying gs://fraud-detection-example/predictions/aarg_fraud_detection_test_nb_v_152287181365/prediction.results-00001-of-00011...\n",
            "/ [1 files][  1.1 MiB/  1.7 MiB]                                                \r/ [2 files][  1.7 MiB/  1.7 MiB]                                                \rCopying gs://fraud-detection-example/predictions/aarg_fraud_detection_test_nb_v_152287181365/prediction.results-00002-of-00011...\n",
            "/ [2 files][  1.7 MiB/  3.0 MiB]                                                \r-\r- [3 files][  3.0 MiB/  3.0 MiB]                                                \rCopying gs://fraud-detection-example/predictions/aarg_fraud_detection_test_nb_v_152287181365/prediction.results-00003-of-00011...\n",
            "- [3 files][  3.0 MiB/  5.4 MiB]                                                \r- [4 files][  5.4 MiB/  5.4 MiB]                                                \r\n",
            "==> NOTE: You are performing a sequence of gsutil operations that may\n",
            "run significantly faster if you instead use gsutil -m -o ... Please\n",
            "see the -m section under \"gsutil help options\" for further information\n",
            "about when gsutil -m can be advantageous.\n",
            "\n",
            "Copying gs://fraud-detection-example/predictions/aarg_fraud_detection_test_nb_v_152287181365/prediction.results-00004-of-00011...\n",
            "- [4 files][  5.4 MiB/  6.0 MiB]                                                \r- [5 files][  6.0 MiB/  6.0 MiB]                                                \rCopying gs://fraud-detection-example/predictions/aarg_fraud_detection_test_nb_v_152287181365/prediction.results-00005-of-00011...\n",
            "- [5 files][  6.0 MiB/  7.4 MiB]                                                \r\\\r\\ [6 files][  7.4 MiB/  7.4 MiB]                                                \rCopying gs://fraud-detection-example/predictions/aarg_fraud_detection_test_nb_v_152287181365/prediction.results-00006-of-00011...\n",
            "\\ [6 files][  7.4 MiB/  8.5 MiB]                                                \r\\ [7 files][  8.5 MiB/  8.5 MiB]                                                \rCopying gs://fraud-detection-example/predictions/aarg_fraud_detection_test_nb_v_152287181365/prediction.results-00007-of-00011...\n",
            "\\ [7 files][  8.5 MiB/  9.9 MiB]                                                \r\\ [8 files][  9.9 MiB/  9.9 MiB]                                                \rCopying gs://fraud-detection-example/predictions/aarg_fraud_detection_test_nb_v_152287181365/prediction.results-00008-of-00011...\n",
            "\\ [8 files][  9.9 MiB/ 12.4 MiB]                                                \r|\r| [9 files][ 12.4 MiB/ 12.4 MiB]                                                \rCopying gs://fraud-detection-example/predictions/aarg_fraud_detection_test_nb_v_152287181365/prediction.results-00009-of-00011...\n",
            "| [9 files][ 12.4 MiB/ 14.7 MiB]                                                \r| [10 files][ 14.7 MiB/ 14.7 MiB]                                               \rCopying gs://fraud-detection-example/predictions/aarg_fraud_detection_test_nb_v_152287181365/prediction.results-00010-of-00011...\n",
            "| [10 files][ 14.7 MiB/ 15.9 MiB]                                               \r/\r/ [11 files][ 15.9 MiB/ 15.9 MiB]                                               \r\n",
            "Operation completed over 11 objects/15.9 MiB.                                    \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "1e4XM_arXtFC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Compute precision-recall curve**\n",
        "\n",
        "We join the labels and precision based on their hash-key (added in the DataFlow step). These are not unique and may have a few duplicates that we get rid of.\n",
        "\n",
        "We then plot the precision-recall curve and the corresponding AUC."
      ]
    },
    {
      "metadata": {
        "id": "RZwkH1KjXtFC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "e8af6075-a353-4b73-87e8-e4526e0a7e70",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522873347339,
          "user_tz": 240,
          "elapsed": 291238,
          "user": {
            "displayName": "Arthur Argenson",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "103507511977375243246"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import json\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "def extract_from_json(path, key, values, proc=(lambda x: x)):\n",
        "  \"\"\"Extracts and parses data from json files and returns a dictionary.\n",
        "\n",
        "  Args:\n",
        "    path: string, path to input data.\n",
        "    key: string, name of key column.\n",
        "    values: string, name of column containing values to extract.\n",
        "    proc: function, used to process values from input. Follows the signature:\n",
        "      * Args:\n",
        "        * x: string or tuple of string\n",
        "      * Returns:\n",
        "        string\n",
        "\n",
        "  Returns:\n",
        "    Dictionary of parsed data.\n",
        "  \"\"\"\n",
        "\n",
        "  res = {}\n",
        "  keys = []\n",
        "  with open(path) as f:\n",
        "    for line in f:\n",
        "      line = json.loads(line)\n",
        "      item_key = proc(line[key])\n",
        "      res[item_key] = line[values]\n",
        "      keys.append(item_key)\n",
        "  unique_keys = [key for key in keys if keys.count(key) == 1]\n",
        "  return {k: res[k] for k in unique_keys}\n",
        "\n",
        "def compute_and_print_pr_auc(labels, probabilities):\n",
        "  \"\"\"Computes statistic on predictions, based on true labels.\n",
        "\n",
        "  Prints precision-recall curve AUC and writes the curve as a JPG image to the\n",
        "  specified directory.\n",
        "\n",
        "  Args:\n",
        "    labels: np.array, vector containing true labels.\n",
        "    probabilities: np.array, 2-dimensional vector containing inferred\n",
        "      probabilities.\n",
        "  \"\"\"\n",
        "\n",
        "  average_precision = average_precision_score(labels, probabilities[:, 1])\n",
        "\n",
        "  precision, recall, _ = precision_recall_curve(labels, probabilities[:, 1])\n",
        "  plt.step(recall, precision, color='b', alpha=0.2, where='post')\n",
        "  plt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\n",
        "  plt.xlabel('Recall')\n",
        "  plt.ylabel('Precision')\n",
        "  plt.ylim([0.0, 1.05])\n",
        "  plt.xlim([0.0, 1.0])\n",
        "  plt.title(\n",
        "    'Precision-Recall curve: AUC={0:0.2f}'.format(average_precision))\n",
        "  plt.plot()\n",
        "  print 'Precision-Recall AUC: {0:0.2f}'.format(average_precision)\n",
        "\n",
        "def run(labels_path, predictions_path):\n",
        "  \"\"\"Reads input data and runs analysis on predictions.\n",
        "\n",
        "  Args:\n",
        "    labels_path: string, path to true labels.\n",
        "    predictions_path: string, path to inferred probabilities.\n",
        "  \"\"\"\n",
        "\n",
        "  labels = extract_from_json(labels_path, 'key', 'Class')\n",
        "  proba = extract_from_json(\n",
        "    predictions_path, 'key', 'probabilities', proc=(lambda x: x[0]))\n",
        "\n",
        "  keys = labels.keys()\n",
        "  labels = np.array([labels[key] for key in keys])\n",
        "  proba = np.array([proba[key] for key in keys])\n",
        "\n",
        "  compute_and_print_pr_auc(\n",
        "    labels=labels, probabilities=proba)\n",
        "\n",
        "run(\n",
        "  labels_path='labels.txt',\n",
        "  predictions_path='predictions.txt')\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision-Recall AUC: 0.70\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEVCAYAAAALsCk2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\neqjynhIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fe75d593b10>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Cs8QN7zPXtFF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}